{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom.datasets import Meiosis_Dataset\n",
    "from custom.models import Net\n",
    "from custom.utils import accuracy, weight_balance\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import ConcatDataset, DataLoader\n",
    "from torch import optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = Meiosis_Dataset(path='../SC_figures', label={'leptotene', 'zygotene', 'pachytene_ab', 'pachytene_n'}, target=[0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = Meiosis_Dataset(path='../SC_figures', label='zygotene', target=0)\n",
    "indicies_1, indicies_2 = random_sample(len(dataset_1), .1)\n",
    "dataset_1_t = Meiosis_Dataset(path='../SC_figures', label='zygotene', target=0)\n",
    "dataset_1_t.im_paths = [dataset_1_t.im_paths[index] for index in indicies_1]\n",
    "dataset_1_v = Meiosis_Dataset(path='../SC_figures', label='zygotene', target=0)\n",
    "dataset_1_v.im_paths = [dataset_1_v.im_paths[index] for index in indicies_2]\n",
    "\n",
    "dataset_2 = Meiosis_Dataset(path='../SC_figures', label='pachytene_ab', target=1)\n",
    "indicies_1, indicies_2 = random_sample(len(dataset_2), .1)\n",
    "dataset_2_t = Meiosis_Dataset(path='../SC_figures', label='pachytene_ab', target=1)\n",
    "dataset_2_t.im_paths = [dataset_2_t.im_paths[index] for index in indicies_1]\n",
    "dataset_2_v = Meiosis_Dataset(path='../SC_figures', label='pachytene_ab', target=1)\n",
    "dataset_2_v.im_paths = [dataset_2_v.im_paths[index] for index in indicies_2]\n",
    "\n",
    "dataset_t = ConcatDataset([dataset_1_t, dataset_2_t])\n",
    "train_loader = DataLoader(dataset_t, batch_size=64, shuffle=True)\n",
    "\n",
    "dataset_v = ConcatDataset([dataset_1_v, dataset_2_v])\n",
    "val_loader = DataLoader(dataset_v, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129 209 338\n",
      "\n",
      " 1.3101\n",
      " 0.8086\n",
      "[torch.FloatTensor of size 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset_1), len(dataset_2), len(dataset))\n",
    "weights = weight_balance([len(dataset_1), \n",
    "                          len(dataset_2)])\n",
    "weights = torch.FloatTensor(weights)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1a): conv_bn(\n",
       "    (conv): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "  )\n",
       "  (conv1b): conv_bn(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "  )\n",
       "  (conv2): inception_v2(\n",
       "    (conv3a): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv3b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv5a): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv5b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv5c): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv7a): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv7b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv7c): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv7d): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "  )\n",
       "  (conv3): inception_v2(\n",
       "    (conv3a): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv3b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv5a): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv5b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv5c): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv7a): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv7b): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv7c): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv7d): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "  )\n",
       "  (conv4): inception_v3(\n",
       "    (conv3a): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv3b): factorize_conv(\n",
       "      (conv_1xn): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
       "      (conv_nx1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
       "    )\n",
       "    (conv5a): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv5b): factorize_conv(\n",
       "      (conv_1xn): Conv2d(64, 64, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))\n",
       "      (conv_nx1): Conv2d(64, 64, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
       "    )\n",
       "    (conv7a): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (conv7b): factorize_conv(\n",
       "      (conv_1xn): Conv2d(64, 64, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0))\n",
       "      (conv_nx1): Conv2d(64, 64, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n",
       "    )\n",
       "    (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True)\n",
       "  )\n",
       "  (conv5): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (mlp1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (mlp2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (mlp3): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net(2)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    acc = 0\n",
    "    for batch_idx, (im, target) in enumerate(train_loader):\n",
    "        input, target, weight = Variable(im).cuda(), Variable(target.squeeze_()).cuda(), Variable(weights).cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input)\n",
    "        loss = loss_func(output, target, weight)\n",
    "        loss.backward()\n",
    "        acc += accuracy(output, target).data[0]\n",
    "        train_loss += loss.data[0]\n",
    "        optimizer.step()\n",
    "        \n",
    "    print('====> Epoch: {} Average loss: {:.4f} Average acc: {:.3f}'.format(\n",
    "          epoch, train_loss / len(train_loader), acc / len(train_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "from torch.nn.functional import threshold\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    for i, (im, target) in enumerate(val_loader):\n",
    "        input, target, weight = Variable(im).cuda(), Variable(target.squeeze_()).cuda(), Variable(weights).cuda()\n",
    "        output = model(input)\n",
    "        loss += loss_func(output, target, weight)\n",
    "        acc += accuracy(output, target).data[0]\n",
    "        test_loss += loss.data[0]\n",
    "        \n",
    "    print('====> Epoch: {} Average loss: {:.4f} Average acc: {:.3f}'.format(\n",
    "          epoch, test_loss / len(val_loader), acc / len(val_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/skimage/morphology/misc.py:122: UserWarning: Only one label was provided to `remove_small_objects`. Did you mean to use a boolean array?\n",
      "  warn(\"Only one label was provided to `remove_small_objects`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1 Average loss: 0.6997 Average acc: 0.558\n",
      "====> Epoch: 2 Average loss: 0.6798 Average acc: 0.604\n",
      "====> Epoch: 3 Average loss: 0.6645 Average acc: 0.630\n",
      "====> Epoch: 4 Average loss: 0.6395 Average acc: 0.637\n",
      "====> Epoch: 5 Average loss: 0.6424 Average acc: 0.662\n",
      "====> Epoch: 6 Average loss: 0.6289 Average acc: 0.623\n",
      "====> Epoch: 7 Average loss: 0.6045 Average acc: 0.690\n",
      "====> Epoch: 8 Average loss: 0.5796 Average acc: 0.700\n",
      "====> Epoch: 9 Average loss: 0.6069 Average acc: 0.682\n",
      "====> Epoch: 10 Average loss: 0.5662 Average acc: 0.766\n",
      "====> Epoch: 11 Average loss: 0.5815 Average acc: 0.706\n",
      "====> Epoch: 12 Average loss: 0.5578 Average acc: 0.718\n",
      "====> Epoch: 13 Average loss: 0.5539 Average acc: 0.697\n",
      "====> Epoch: 14 Average loss: 0.4924 Average acc: 0.797\n",
      "====> Epoch: 15 Average loss: 0.5355 Average acc: 0.767\n",
      "====> Epoch: 16 Average loss: 0.4866 Average acc: 0.768\n",
      "====> Epoch: 17 Average loss: 0.4721 Average acc: 0.782\n",
      "====> Epoch: 18 Average loss: 0.5263 Average acc: 0.768\n",
      "====> Epoch: 19 Average loss: 0.4833 Average acc: 0.766\n",
      "====> Epoch: 20 Average loss: 0.5198 Average acc: 0.723\n",
      "====> Epoch: 21 Average loss: 0.4961 Average acc: 0.743\n",
      "====> Epoch: 22 Average loss: 0.4252 Average acc: 0.803\n",
      "====> Epoch: 23 Average loss: 0.4193 Average acc: 0.819\n",
      "====> Epoch: 24 Average loss: 0.4430 Average acc: 0.768\n",
      "====> Epoch: 25 Average loss: 0.4068 Average acc: 0.797\n",
      "====> Epoch: 26 Average loss: 0.4020 Average acc: 0.825\n",
      "====> Epoch: 27 Average loss: 0.3266 Average acc: 0.858\n",
      "====> Epoch: 28 Average loss: 0.3302 Average acc: 0.881\n",
      "====> Epoch: 29 Average loss: 0.3162 Average acc: 0.862\n",
      "====> Epoch: 30 Average loss: 0.3003 Average acc: 0.873\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "epochs = 30\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './models/period_classification_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
